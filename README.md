# üîç Core Concepts: Understanding Tensors in Python and Beyond

Welcome to my **Core Concepts** series, where we explore the fundamentals of machine learning and deep learning. This page is dedicated to understanding **tensors**, starting from Python lists and progressing through various popular frameworks like **NumPy**, **PyTorch**, and **TensorFlow**.


## üìö Table of Contents
- [0. Installation](#0-installation)
- [1. What is a Tensor?](#1-what-is-a-tensor)
- [2. Python Lists as Basic Tensors](#2-python-lists-as-basic-tensors)
- [2.1. Limitations of Python Lists](#21-limitations-of-python-lists)
- [3. NumPy Arrays: Enhanced Tensor Operations](#3-numpy-arrays-enhanced-tensor-operations)
- [4. Limitations of NumPy for Tensors](#4-limitations-of-numpy-for-tensors)
- [5. Tensors in PyTorch](#5-tensors-in-pytorch)
- [6. Tensors in TensorFlow](#6-tensors-in-tensorflow)
- [7. Comparative Analysis of Tensors Across Frameworks](#7-comparative-analysis-of-tensors-across-frameworks)

## 0. Installation

pip install -r requirements.txt

## 1. What is a Tensor?

The term **tensor** can have different meanings depending on the context. It's important to understand the distinction between **mathematical tensors** and **tensors in machine learning (ML) and deep learning (DL)**.

### Mathematical Tensors:
In **mathematics**, a tensor is a generalization of scalars, vectors, and matrices, and it can be thought of as a multi-dimensional array. Tensors in mathematics often have more complex properties, particularly related to **coordinate transformations**. They are used in fields such as **differential geometry**, **general relativity**, and other advanced areas of mathematics. Tensors in this context are concerned with how they transform under changes in the coordinate system, which gives them their rich structure and abstract behavior.

Mathematical tensors are often classified by their **rank** or **order** (number of dimensions):
- **Scalar (0D tensor)**: A single value (e.g., `5`, `-3.2`).
- **Vector (1D tensor)**: A list or array of numbers (e.g., `[1, 2, 3]`).
- **Matrix (2D tensor)**: A grid of numbers arranged in rows and columns (e.g., `[[1, 2], [3, 4]]`).
- **Higher-dimensional tensors (nD)**: These are multi-dimensional arrays, extending the idea of matrices into more than two dimensions (e.g., 3D arrays like image data with width, height, and channels).

### Tensors in ML/DL:
In **machine learning** and **deep learning**, the term "tensor" is used more loosely to refer to **multi-dimensional arrays**. These can be:
- **Scalars (0D)**: Single numbers (e.g., a loss value).
- **Vectors (1D)**: A sequence of numbers (e.g., weights of a model).
- **Matrices (2D)**: A 2D grid of numbers (e.g., input data to a neural network layer).
- **Higher-dimensional arrays (nD)**: Data with 3 or more dimensions (e.g., an image represented as a 3D array with width, height, and color channels).

In this context, **tensors** are not concerned with the coordinate transformations that are central to their mathematical meaning. Instead, they are primarily used as data structures to store and manipulate data efficiently. In **PyTorch** and **TensorFlow**, the term "tensor" is used to describe any multi-dimensional array, regardless of its dimensionality or mathematical properties.

### Key Difference:
- **Mathematical tensors**: These are abstract objects with additional structure related to coordinate transformations.
- **Tensors in ML/DL**: These are simply multi-dimensional arrays used to represent data.

---

## 2. Python Lists as Basic Tensors
In Python, we can represent a tensor using nested lists. However, Python lists are not optimized for mathematical operations and can be inefficient for large datasets.

**[Code Example](notebooks/1_tensor_basic_arithmetic_operations.ipynb)**

### 2.1 Limitations of Python Lists
- Slow performance for large datasets.
- No optimized mathematical operations.
- Limited support for multi-dimensional operations.

## 3. NumPy Arrays: Enhanced Tensor Operations
**NumPy** provides an efficient and flexible array type that serves as a basic form of tensors. 

**[Code Example](notebooks/1_tensor_basic_arithmetic_operations.ipynb)**

## 4. Limitations of NumPy for Tensors
- No GPU support.
- Lacks automatic differentiation.

## 5. Tensors in PyTorch
**PyTorch** introduces the `torch.Tensor` class, supporting GPU acceleration and automatic differentiation.

**[Code Example](notebooks/1_tensor_basic_arithmetic_operations.ipynb)**

## 6. Tensors in TensorFlow
**TensorFlow** has the `tf.Tensor` class for building and training neural networks.

**[Code Example](notebooks/1_tensor_basic_arithmetic_operations.ipynb)**

## 7. Tensors: A Comparison Across Frameworks

This table compares key features of **Python Lists**, **NumPy Arrays**, **PyTorch Tensors**, and **TensorFlow Tensors**. It helps to understand the capabilities and limitations of each data structure when working with machine learning and numerical computations.

## Feature Comparison Table

| Feature                          | Python List | NumPy Array | PyTorch Tensor | TensorFlow Tensor |
|----------------------------------|-------------|-------------|----------------|-------------------|
| **Basic Operations**             | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **GPU Support**                  | ‚ùå          | ‚ùå          | ‚úÖ             | ‚úÖ                |
| **Automatic Differentiation**    | ‚ùå          | ‚ùå          | ‚úÖ             | ‚úÖ                |
| **Element-wise Operations**      | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Multidimensional Support**     | ‚úÖ (Nested lists) | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Memory Efficiency**            | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Performance (Large Data)**     | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Ease of Use**                  | ‚úÖ (Simple) | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Broadcasting**                 | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Integration with ML/DL Libraries** | ‚ùå      | ‚úÖ          | ‚úÖ             | ‚úÖ                |
| **Parallel Computation**         | ‚ùå          | ‚ùå          | ‚úÖ             | ‚úÖ                |
| **Community Support**            | ‚ùå          | ‚úÖ          | ‚úÖ             | ‚úÖ                |

## Explanation of the Features

### 1. **Basic Operations**
Can you perform basic mathematical operations on the structure? 
- Python lists cannot perform mathematical operations efficiently.
- **NumPy**, **PyTorch**, and **TensorFlow** are optimized for basic tensor operations such as addition, multiplication, etc.

### 2. **GPU Support**
Does the framework support GPU acceleration?
- **Python Lists** do not support GPU acceleration.
- **PyTorch** and **TensorFlow** offer GPU support for faster computations on large datasets and models.

### 3. **Automatic Differentiation**
Automatic differentiation is essential for machine learning and deep learning, particularly during backpropagation in neural networks.
- **Python Lists** do not support automatic differentiation.
- **PyTorch** and **TensorFlow** have built-in support for autograd, which enables automatic differentiation.

### 4. **Element-wise Operations**
Can you perform operations on each element of the tensor, such as multiplying each element by a constant?
- **Python Lists** do not support efficient element-wise operations.
- **NumPy**, **PyTorch**, and **TensorFlow** efficiently handle element-wise operations on tensors and arrays.

### 5. **Multidimensional Support**
How well does the framework handle multidimensional data (e.g., 2D matrices, 3D tensors)?
- **Python Lists** can handle multidimensional data using nested lists, but it is not efficient for large-scale numerical tasks.
- **NumPy**, **PyTorch**, and **TensorFlow** natively support multidimensional data structures (tensors) with optimized memory layouts.

### 6. **Memory Efficiency**
How efficiently does the framework manage memory for large datasets?
- **Python Lists** are not memory-efficient, especially when handling large data.
- **NumPy**, **PyTorch**, and **TensorFlow** use more efficient memory management techniques to handle large-scale computations.

### 7. **Performance (Large Data)**
How well does the framework perform with large datasets?
- **Python Lists** are not optimized for handling large data.
- **NumPy**, **PyTorch**, and **TensorFlow** are highly optimized for performance when working with large datasets, making them suitable for machine learning applications.

### 8. **Ease of Use**
How easy is it to use the framework for tensor operations?
- **Python Lists** are very simple and intuitive, but they lack the functionality needed for efficient numerical operations.
- **NumPy**, **PyTorch**, and **TensorFlow** all provide intuitive and user-friendly APIs for tensor operations.

### 9. **Broadcasting**
Broadcasting allows you to perform operations between tensors of different shapes.
- **Python Lists** do not support broadcasting.
- **NumPy**, **PyTorch**, and **TensorFlow** all support broadcasting, allowing operations on tensors of different shapes without explicit resizing.

### 10. **Integration with ML/DL Libraries**
Can the framework be easily integrated into machine learning or deep learning libraries?
- **Python Lists** are not optimized for integration into machine learning libraries.
- **NumPy**, **PyTorch**, and **TensorFlow** are the backbone of many machine learning and deep learning frameworks, offering seamless integration.

### 11. **Parallel Computation**
Does the framework support parallel computation for faster processing?
- **Python Lists** do not support parallel computation.
- **PyTorch** and **TensorFlow** offer support for parallel computations, which are essential for training models efficiently.

### 12. **Community Support**
How active and large is the community supporting the framework?
- **Python Lists** have limited support for numerical computing tasks.
- **NumPy**, **PyTorch**, and **TensorFlow** all have large and active communities that provide tutorials, troubleshooting help, and resources for learning.

## Comparing Speed Across Frameworks for Basic Operations

In this section, we compare the speed of basic tensor operations (such as element-wise addition and multiplication) across four frameworks:
- **Python Lists**
- **NumPy Arrays**
- **PyTorch Tensors**
- **TensorFlow Tensors**

We will measure the time it takes to perform the same operation (e.g., adding a scalar to every element of a large tensor) in each framework and compare the performance. This helps to highlight the efficiency of specialized tensor libraries.

### Why Benchmark?
Python lists are general-purpose containers, not optimized for numerical computation. Libraries like **NumPy**, **PyTorch**, and **TensorFlow** are designed specifically for fast numerical operations, making them much faster for tasks involving large datasets or complex mathematical functions. By performing basic operations across these frameworks, we will see how performance scales with dataset size and operation complexity.

### Benchmark Methodology
For this benchmark, we will:
1. Create a tensor with **1 million** elements in each framework.
2. Perform an **element-wise addition** operation (e.g., adding a scalar value of 2).
3. Record the time it takes to complete the operation in each framework using the built-in `time` module.

We will use the following test case:
- **Tensor size**: 1,000,000 elements (1D array)
- **Operation**: Scalar addition (e.g., adding 2 to every element)

**[Comparative Code Example](notebokks/5_tensor_comparison.py)**

## üîó Additional Links
- [LinkedIn](https://www.linkedin.com/in/soeren-brockmann-9a911a68/)
- [Website](https://www.sbrockmann.com)

---
Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/soeren-brockmann-9a911a68/).